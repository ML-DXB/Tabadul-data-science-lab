{"cells": [{"metadata": {"id": "fdbcec80-d59f-42ad-a6ab-4366934f63ca"}, "cell_type": "markdown", "source": "### Predicting Customer Churn\nThis notebook performs these steps:<br/>\n1. Builds a scikit-learn model to predict customer churn\n2. Stores the model into the project\n3. Stores the model into the deployment space\n4. Creates and test an Online Deployement for the model\n5. Creates and test a Batch Deployment for the model"}, {"metadata": {"id": "1602dd9a-b3c0-4e7b-98e4-45f4a04c26a2"}, "cell_type": "markdown", "source": "### Environment Setup"}, {"metadata": {"id": "b1adfe83-8bb5-401f-ba8d-86536b1d979d"}, "cell_type": "code", "source": "!pip install sklearn-pandas\n# Update WML library\n!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {"id": "349d684c-261c-4fe3-aaed-2cde3145602b"}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom datetime import datetime\nimport sklearn.pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, LabelBinarizer, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nimport json, requests\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "b6b3d0e0-318f-4a42-8980-435776b92659"}, "cell_type": "markdown", "source": "### Step 1: Load data \nInsert <b><font color=blue>your own</font></b> values for the <b>ibm_api_key_id</b> and <b>bucket name</b> in the appropriate places of the two cells below  "}, {"metadata": {"id": "e2408922-2698-46e8-ab73-9f435fe25c40"}, "cell_type": "code", "source": "from ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space()\n\nimport pandas as pd\n\ncustomer_churn = pd.read_csv(wslib.mount.get_data_path('churn.csv'))\ncustomer_churn.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "4a463092-0807-470e-adfa-2c7674d7b3b4"}, "cell_type": "code", "source": "customer = pd.read_csv('/project_data/data_asset/customer-profile.csv')\ncustomer.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "d457d132-8d81-4531-b276-071c95db2143"}, "cell_type": "markdown", "source": "### Step 2: Merge Files"}, {"metadata": {"id": "ea1d66de-a636-45ef-b65b-1c3c4adcab8f"}, "cell_type": "code", "source": "data = pd.merge(customer, customer_churn, on='ID')", "execution_count": null, "outputs": []}, {"metadata": {"id": "e0e06562-17d3-4a1c-8abd-d6bde9e1901a"}, "cell_type": "markdown", "source": "### Step 3: Rename some columns\nThis step is to remove spaces from columns names, it's an example of data preparation that you may want to do before creating a model. "}, {"metadata": {"id": "904a3ccf-43e8-4056-a2ad-59f6463fadff"}, "cell_type": "code", "source": "data.columns", "execution_count": null, "outputs": []}, {"metadata": {"id": "54d41d54-5e7f-47d9-bf1e-2b3e1be00807"}, "cell_type": "code", "source": "data.rename(columns={'Est Income':'EstIncome', 'Car Owner':'CarOwner' }, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "68d2dc86-40a6-41c9-8d17-cf280dcf3a0e"}, "cell_type": "code", "source": "data.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "id": "b963cd75-6ed2-4098-85b1-009032627905"}, "cell_type": "code", "source": "data.shape", "execution_count": null, "outputs": []}, {"metadata": {"id": "76d02b733ae249c682577fe70273f612"}, "cell_type": "code", "source": "# Uncomment if you would like to see the profile report\n\n#Uncomment and run once to install the package in your runtime environment\n#!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip", "execution_count": null, "outputs": []}, {"metadata": {"id": "7e716826f79d46c98ba2f99c24fcf6de"}, "cell_type": "code", "source": "# Uncomment if you would like to see the profile report\n#from pandas_profiling import ProfileReport\n    \n#profile = ProfileReport(data, title=\"Data Profiling Report\")\n#profile.to_widgets()", "execution_count": null, "outputs": []}, {"metadata": {"id": "841fd753-6f1e-418d-ba13-5727e3f42b32"}, "cell_type": "markdown", "source": "### Step 4: Data understanding"}, {"metadata": {"scrolled": true, "id": "16145cc1-0434-4039-9946-d47044c2446a"}, "cell_type": "code", "source": "data.describe()", "execution_count": null, "outputs": []}, {"metadata": {"id": "8f0e6e9a-ce29-40de-9cc4-b8cf5638af10"}, "cell_type": "code", "source": "g1 = sns.countplot(data=data, x='CHURN', order=data.CHURN.value_counts().index)\nplt.title('Customer Churn Rates')\nplt.ylabel('Count of Churn')\nplt.ylim(0, 800)\n#Add percentages to the graph\ntotal = float(len(data)) #one person per row\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()/2.,\n            height + 1,\n            '{0:.0%}'.format(height/total),\n            ha=\"center\") \nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "d0d9bcec-6696-4051-b1d7-489685db70c0"}, "cell_type": "code", "source": "sns.catplot(x=\"CHURN\", y=\"AvgMonthlySpend\",\n                 hue=\"MembershipPlan\", col=\"Paymethod\",\n                 data=data, kind='box',\n                 height=7, aspect=.81);", "execution_count": null, "outputs": []}, {"metadata": {"id": "a2d1e45e-4ad4-434c-bb8c-e31da639186c"}, "cell_type": "markdown", "source": "### Step 5: Build the sklearn pipeline and the Random Forest model\n"}, {"metadata": {"id": "e9cf7c1f-8a08-46a8-9f6a-c162a7d1d053"}, "cell_type": "code", "source": "# Define input data to the model\nX = data.drop(['ID','CHURN'], axis=1)", "execution_count": null, "outputs": []}, {"metadata": {"id": "4d769977-8ab6-4e2b-8680-2167e64cde53"}, "cell_type": "code", "source": "# Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\nle = LabelEncoder()\ny = le.fit_transform(data['CHURN'])", "execution_count": null, "outputs": []}, {"metadata": {"id": "12eedbbd-92cd-49bf-b733-1fa134a03156"}, "cell_type": "code", "source": "label_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {"id": "048a51dc-b914-48d3-bb5f-2233deb88525"}, "cell_type": "code", "source": "# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b4285381-d874-404c-af2c-8b14c26dc238"}, "cell_type": "markdown", "source": "#### Use the DataFrameMapper class to declare transformations and variable imputations.\n\n* LabelBinarizer - Converts a categorical variable into a dummy variable (aka binary variable)\n* StandardScaler - Standardize features by removing the mean and scaling to unit variance, z = (x - u) / s\n\nSee docs: \n* https://github.com/scikit-learn-contrib/sklearn-pandas\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer\n* https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"}, {"metadata": {"id": "2e7b7b00-6bda-49f8-9d3b-e5c0c631763f"}, "cell_type": "code", "source": "\nmapper_good = DataFrameMapper([\n    (['Gender'], LabelBinarizer()),\n    (['Status'], LabelBinarizer()),\n    (['CarOwner'], LabelBinarizer()),\n    (['Paymethod'], LabelBinarizer()),\n    (['MembershipPlan'], LabelBinarizer()),\n    (['Children'],  StandardScaler()),\n    (['EstIncome'],  StandardScaler()),\n    (['Age'],  StandardScaler()),\n    (['AvgMonthlySpend'],  StandardScaler()),\n    (['CustomerSupportCalls'],  StandardScaler())], default=False)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "cde3a0fb-a94c-4ffe-9e67-738f530e1393"}, "cell_type": "code", "source": "# Instantiate the Classifier\nrandom_forest = RandomForestClassifier(random_state=5)\n\n# Define the steps in the pipeline to sequentially apply a list of transforms and the estimator, i.e. RandomForestClassifier\nsteps = [('mapper', mapper_good),('RandonForestClassifier', random_forest)]\npipeline = sklearn.pipeline.Pipeline(steps)\n\n# train the model\nmodel=pipeline.fit( X_train, y_train )\n\nmodel", "execution_count": null, "outputs": []}, {"metadata": {"id": "682dcda1-361e-40fb-92c3-c969c7bfe09f"}, "cell_type": "code", "source": "# Display Label Mapping to assist with interpretation of the model\nlabel_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {"id": "0417c96c-e739-4399-9504-d9ec25060c74"}, "cell_type": "code", "source": "### call pipeline.predict() on your X_test data to make a set of test predictions\ny_prediction = pipeline.predict( X_test )\n\n### test your predictions using sklearn.classification_report()\nreport = sklearn.metrics.classification_report( y_test, y_prediction )\n\n### and print the report\nprint(report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a49aa053-e5c8-4fd7-8235-d7a03ea8baa3"}, "cell_type": "markdown", "source": "###  Step 6:  Tune the model to find the best model"}, {"metadata": {"id": "d044a653-85e0-4d64-9ae6-05c5bb2a272b"}, "cell_type": "code", "source": "# List keys to the model param to tune\n#model.get_params().keys()", "execution_count": null, "outputs": []}, {"metadata": {"id": "70a5c354-1a2a-478e-a016-ec81112fa08b"}, "cell_type": "code", "source": "parameters = { 'RandonForestClassifier__max_depth': [5,8,10],\n               'RandonForestClassifier__n_estimators': [150,180,200]}", "execution_count": null, "outputs": []}, {"metadata": {"id": "91eb14c6-1150-47c8-82b3-76511d87c5e6"}, "cell_type": "code", "source": "grid_obj = GridSearchCV(estimator=model, param_grid=parameters,  cv=3)", "execution_count": null, "outputs": []}, {"metadata": {"id": "3c02d873-6f07-41e4-9386-26dc2fc75ec9"}, "cell_type": "code", "source": "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train,y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "4a41298c-5820-40ad-aed9-fda904c24ebf"}, "cell_type": "code", "source": "# Get the estimator\nbest_clf = grid_fit.best_estimator_", "execution_count": null, "outputs": []}, {"metadata": {"id": "82870f23-70f8-48ce-8fe0-8fe4dcafd357"}, "cell_type": "code", "source": "best_predictions = best_clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {"id": "c90eee8d-f6f2-4a07-a0dc-04d515fa2618"}, "cell_type": "code", "source": "best_predictions_report = sklearn.metrics.classification_report( y_test, best_predictions )", "execution_count": null, "outputs": []}, {"metadata": {"id": "ec487b2d-fa8c-4923-8fe9-76c668dace95"}, "cell_type": "code", "source": "print('Results of best fitted model: \\n\\n',best_predictions_report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "4c05d175-2090-4329-bd8a-6f11956e4da6"}, "cell_type": "code", "source": "print('Results of default model: \\n\\n',report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a1e761ee-150f-4191-9017-b935dbb2ad9e"}, "cell_type": "code", "source": "m_step=pipeline.named_steps['mapper']", "execution_count": null, "outputs": []}, {"metadata": {"id": "547dc3f8-7fd4-4383-b762-87d9a38ffd4b"}, "cell_type": "code", "source": "m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {"id": "06dcf01c-721c-4e77-aa0e-04b6bcf7b64f"}, "cell_type": "code", "source": "features = m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {"id": "e92bc724-f4f3-4e70-a7d5-95281adf64f0"}, "cell_type": "code", "source": "# Get the features importance\nimportances = pipeline.named_steps['RandonForestClassifier'][1].feature_importances_\nindices = np.argsort(importances)", "execution_count": null, "outputs": []}, {"metadata": {"id": "23b4bed7-203b-4515-8cb6-b16e54ecb48a"}, "cell_type": "code", "source": "plt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b',align='center')\nplt.yticks(range(len(indices)), (np.array(features))[indices])\nplt.xlabel('Relative Importance')", "execution_count": null, "outputs": []}, {"metadata": {"id": "a5f14fcc-1698-4151-9b6d-32210da8cfe9"}, "cell_type": "markdown", "source": "### Step 7: Save Model in the Project and WML Deployment Space\n"}, {"metadata": {"id": "74468636-0907-47e7-bd5d-79cb304a76ad"}, "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-info\">\nYou have a choice to either save the model in the <b>project</b> OR the <b>deployment space</b>:<br><br>\n    <li> If you're saving your model in your project, you have to set the default project using the python client.</li><br>\n    <li>If you're saving the model in the deployment space, first, we will check if an existing deployment space is already associated with this project and set the associated deployment space as the default space.  If this project is not yet associated with a deployment space, we will create a deployment space.. From there you'll be able to deploy and score the model in your deployment space.</li></div>\n"}, {"metadata": {"id": "e1a6f5aa-2ac2-4a76-bdef-f96934bbc9cf"}, "cell_type": "code", "source": "# get the Project ID and set the location to save the model to the project\nfrom ibm_watson_machine_learning import APIClient\nimport os\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"4.0\"\n}\n\nclient = APIClient(wml_credentials)\n\nproject_id = os.environ['PROJECT_ID']\nclient.set.default_project(project_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "c3800b51-60c1-4088-acab-0a4bfd60c1da"}, "cell_type": "code", "source": "# Note - this step is commented out because we are saving to a Deployment Space. If you would like to save to the project instead, comment out the code. \n# The \"pc\" object is generated by \"Insert project token\" action from the top menu. Make sure to insert the code and run it if you want to save to the project. \n# client.set.default_project(pc.project_id)\n\n# IMPORTANT\n# Replace the space_uid value with the Space ID that you looked up on the Settings tab of your Deployment Space\nspace_uid='replace_with_your_space_id'\n\n# Set default project and space. When we invoke the store_model function in the next cell, it will save the model to the specified project and space\nclient.set.default_space(space_uid)", "execution_count": null, "outputs": []}, {"metadata": {"id": "26bd6734-26b8-42fa-a1b9-c7311578fb54"}, "cell_type": "code", "source": "# Provide metadata and save the model into the repository. After running this cell, the model will be displayed in the Assets view\n\n# Model Metadata\n\nmodel_name = 'customer_churn_model_1'\nsoftware_spec_uid = client.software_specifications.get_uid_by_name('default_py3.7_opence')\n\nmetadata = {\n    client.repository.ModelMetaNames.NAME: model_name,\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.23\"\n}\n\nstored_model_details = client.repository.store_model(pipeline,\n                                               meta_props=metadata,\n                                               training_data=X_train,\n                                               training_target=y_train)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cdbfc9d5-2778-4131-b0db-0d57328e859e"}, "cell_type": "markdown", "source": "You can choose to stop here, navigate to the project and promote/deploy the saved model into the deployment space using the UI, or continue executing the code cells belows to deploy the model programmatically."}, {"metadata": {"id": "2a71c2dd-f2d9-495b-a197-6744652bba0e"}, "cell_type": "markdown", "source": "### Step 8: Create an Online Deployment for the stored model"}, {"metadata": {"id": "e86c883a-1682-4501-9127-0bf83e73c358"}, "cell_type": "code", "source": "model_uid = client.repository.get_model_uid(stored_model_details)\ndeployment = client.deployments.create(\n    artifact_uid=model_uid,\n    meta_props={\n        client.deployments.ConfigurationMetaNames.NAME: \"Churn Deployment via API-Online\",\n        client.deployments.ConfigurationMetaNames.ONLINE:{}}\n)", "execution_count": null, "outputs": []}, {"metadata": {"id": "162f91aa-3040-4c0e-9938-277dfed9bceb"}, "cell_type": "markdown", "source": "### Step 8. Test the Online Deployment By Sending a Score Request (with data) to the Scoring Endpoint"}, {"metadata": {"id": "5af2d6da-c16d-4dac-84b0-53d98823d2f5"}, "cell_type": "code", "source": "deployment_id = client.deployments.get_id(deployment)", "execution_count": null, "outputs": []}, {"metadata": {"id": "97cf38e3-993d-4367-b7b0-7981ff2e0d74"}, "cell_type": "code", "source": "scoring_data = {\n    client.deployments.ScoringMetaNames.INPUT_DATA: [\n        {\n            'fields': ['Gender', 'Status', 'Children', 'EstIncome', 'CarOwner', 'Age', 'AvgMonthlySpend', 'CustomerSupportCalls', 'Paymethod', 'MembershipPlan'],\n            'values': [['M','S',2.0,25000,'Y',25,10,1,'CC',1]]\n        }]\n}\n\npredictions = client.deployments.score(deployment_id, scoring_data)\nprint(predictions)", "execution_count": null, "outputs": []}, {"metadata": {"id": "6d141357-d538-4788-a80a-11923c308e67"}, "cell_type": "code", "source": "# get the predicted value and reverse the label transformation\npredicted_value = predictions.get('predictions')[0].get('values')[0][0]\nle.inverse_transform([predicted_value])", "execution_count": null, "outputs": []}, {"metadata": {"id": "3561c840-edea-4664-a410-57dcab60dd46"}, "cell_type": "markdown", "source": "### Step 9: Create a Batch Deployment for the stored model"}, {"metadata": {"id": "0312d452-c887-46eb-b81f-689fd462545a"}, "cell_type": "code", "source": "# Choose a Deployment Name & Tag for the BATCH Deployment\n\ndeployment_name = \"Churn Deployment via API-Batch\"\ndeployment_desc = 'Churn Model deployed for Batch scoring using a small configuration'", "execution_count": null, "outputs": []}, {"metadata": {"id": "8aaacac9-cb07-4a79-9da4-4c21197f98d2"}, "cell_type": "code", "source": "# Create the deployment metadata and then create the BATCH deployment\n\n# Create the metedata\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: deployment_desc,\n    client.deployments.ConfigurationMetaNames.BATCH: {},\n    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC:{\n         \"name\": \"XS\",       # XS, S, M, L, XL\n         \"nodes\": 2\n     }\n}\n\n# Create the deployment\n#model_uid = published_model_details[\"metadata\"][\"id\"]\ndeployment_details = client.deployments.create( artifact_uid=model_uid, meta_props=meta_props)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cd0e6743-b8b2-4a39-9ec0-f6e6326486e6"}, "cell_type": "markdown", "source": "### Step 10: Create a Job to run the Batch Deployment"}, {"metadata": {"id": "8a8f88ec-1f65-490d-a91f-5a4197201f6c"}, "cell_type": "markdown", "source": "#### Obtain the BATCH Deployment UID"}, {"metadata": {"id": "ab575a4c-d391-4674-ae46-b8c1085025cf"}, "cell_type": "code", "source": "deployment_details", "execution_count": null, "outputs": []}, {"metadata": {"id": "da8004a3-ebfa-4b0f-86b7-719504034c72"}, "cell_type": "code", "source": "# Obtain the BATCH Deployment UID from the batch deployment details - the job needs to be linked to the batch deployment it is going to run\n\nbatch_deployment_uid = deployment_details[\"metadata\"][\"id\"]\nbatch_deployment_uid", "execution_count": null, "outputs": []}, {"metadata": {"id": "7beac196-6985-476b-ae83-11b02af192f5"}, "cell_type": "markdown", "source": "#### Obtain the Data Asset Information Required to Create the Job\n\n<font color = blue>This examples assumes that the input file for batch scoring \"new_customers.csv\" is already in the deployment space.<br>\nWhilst files/data connections can be promoted to the deployment space using APIs, this file was manually promoted to the deployment space for the GUI based deployment earlier in the lab.</font>"}, {"metadata": {"id": "7d2a78f7-bc8b-470b-bb11-8da2e0e0b2cb"}, "cell_type": "code", "source": "client.data_assets.list()", "execution_count": null, "outputs": []}, {"metadata": {"id": "2475fd6c-1113-486b-89e7-00b6bbb22273"}, "cell_type": "code", "source": "#copy the data file name and asset id from the output in the previous cell to the commands below:\ninput_file = 'new_customers.csv'                     #update this filename if you are not using the default file promoted in the last section of the lab\nasset_id = 'replace_with_id_from_the_output_above'", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "id": "e2d0bde9-d6d1-4326-aa56-0162724e77ce"}, "cell_type": "code", "source": "data_asset = client.data_assets.get_details(asset_id)\ninput_data_href = client.data_assets.get_href(data_asset)\nprint('Input Data HREF is: ' + str(input_data_href))\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "0a38e09e-e7f3-4bc3-a569-67fe3b7983da"}, "cell_type": "markdown", "source": "#### Create the JOB Payload metadata"}, {"metadata": {"id": "44116a77-0f47-4f72-811f-517bd5a9bf70"}, "cell_type": "code", "source": "# Specify the name and description of the CSV file which will contain the results of the scoring process\nbatch_output_file = \"Churn Results - Batch API.csv\"\nbatch_output_desc = \"Data file containing the scoring results of the churn model processed via API\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "010d9f72-993b-4b46-b79c-898dd2c5ab7a"}, "cell_type": "code", "source": "# Specify the input\n\n\njob_payload_ref = {\n    client.deployments.ScoringMetaNames.INPUT_DATA_REFERENCES: [{\n        \"name\": input_file,\n        \"type\": \"data_asset\",\n        \"connection\": {},\n        \"location\": {\n                      \"href\":  input_data_href\n                    }\n    }],\n    client.deployments.ScoringMetaNames.OUTPUT_DATA_REFERENCE: {       \n            \"type\": \"data_asset\",\n            \"connection\": {},\n            \"location\": {\n                \"name\": batch_output_file,\n                \"description\": batch_output_desc\n            }\n        }\n}", "execution_count": null, "outputs": []}, {"metadata": {"id": "3eb82b4e-be1c-4174-ba33-0ae0efa158e2"}, "cell_type": "markdown", "source": "#### Create the JOB\n<font color=blue><b>Note:</b> The JOB automatically executes upon creation</font><br><br>\n"}, {"metadata": {"id": "bde1ab8b-d403-42af-8ca6-f9cb13ffab2e"}, "cell_type": "code", "source": "# Create the job\n\njob = client.deployments.create_job(deployment_id=batch_deployment_uid,meta_props=job_payload_ref)", "execution_count": null, "outputs": []}, {"metadata": {"id": "3def4543-d76f-493e-b188-99a1a8bfbc58"}, "cell_type": "markdown", "source": "#### Check to see if the job has successfully completed"}, {"metadata": {"id": "06cc52b5-7b0a-4080-93d7-2bc3699937c0"}, "cell_type": "code", "source": "#Find the job ID\n\njob_id = client.deployments.get_job_uid(job)\nprint(job_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "49dd8fb6-00d3-4ab9-b7be-9e92100eeb3e"}, "cell_type": "code", "source": "#Find the status of the job which has just been created and executed\nclient.deployments.get_job_status(job_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d5bcb1b0-b3c6-4b0c-89c5-ec50e11c522e"}, "cell_type": "markdown", "source": "**Author:**  Sidney Phoon and Elena Lowery <br/>\n**Date:**  September 2021"}, {"metadata": {"id": "513fbf3303ae463c9cf25ae02d6eebeb"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}