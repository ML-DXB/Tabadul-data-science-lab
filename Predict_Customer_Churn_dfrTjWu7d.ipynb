{"cells": [{"metadata": {"id": "5acf0c34-5472-4bd0-b2ac-5a2a7aeb59e2"}, "cell_type": "markdown", "source": "### Predicting Customer Churn"}, {"metadata": {"id": "daa8cd58-109c-4dfa-a48e-3df7a7159a93"}, "cell_type": "markdown", "source": "### Environment Setup"}, {"metadata": {"id": "d98bea58-ffe6-4ee2-a09e-03655bd12bdc"}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install sklearn-pandas", "execution_count": null, "outputs": []}, {"metadata": {"id": "47e10e67-17ae-4ae2-962d-33b82ca61fa6"}, "cell_type": "code", "source": "!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {"id": "b2daf929-eaea-4079-8357-638d8e7fc737"}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport pandas_profiling\nimport sklearn.pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, LabelBinarizer, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nimport json\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "bd2b6f93-3d53-4bc0-9d1f-da3f64283d43"}, "cell_type": "markdown", "source": "### Step 1: Load data \n\n#### 1.1: Download the data files"}, {"metadata": {"id": "9796508f905d443bb83e184834def282"}, "cell_type": "code", "source": "from ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space()\n\nimport pandas as pd\n\ncustomer_churn = pd.read_csv(wslib.mount.get_data_path('churn.csv'))\ncustomer_churn.head()\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "3400a52c02224586a9fd043316cbffb0"}, "cell_type": "code", "source": "customer = pd.read_csv(wslib.mount.get_data_path('customer-profile.csv'))\ncustomer.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "e2a2c2fa-b361-4db9-b393-2699f824c466"}, "cell_type": "code", "source": "customer = pd.read_csv('/project_data/data_asset/customer-profile.csv')\ncustomer.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "8a4a1745-d743-4a08-a86a-1bfd6d5bc94d"}, "cell_type": "markdown", "source": "### Step 2: Merge Files"}, {"metadata": {"id": "c7595a2a-8091-4181-af59-d644d6c35e65"}, "cell_type": "code", "source": "data = pd.merge(customer, customer_churn, on='ID')", "execution_count": null, "outputs": []}, {"metadata": {"id": "9f429e93-3f3c-4075-990a-416fe2f7869c"}, "cell_type": "markdown", "source": "### Step 3: Rename some columns\nThis step is to remove spaces from columns names, it's an example of data preparation that you may want to do before creating a model. "}, {"metadata": {"id": "50d7b359-8267-4a82-ad38-83e4e86c3b74"}, "cell_type": "code", "source": "data.columns", "execution_count": null, "outputs": []}, {"metadata": {"id": "6275f43c-5393-429f-9d98-d8245382e337"}, "cell_type": "code", "source": "data.rename(columns={'Est Income':'EstIncome', 'Car Owner':'CarOwner' }, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "374a042c-2ed0-4276-9feb-b2b02aa534cd"}, "cell_type": "code", "source": "data.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "a6df84ae-4f75-442a-9dee-243c00dc9fb7", "scrolled": true}, "cell_type": "code", "source": "data.shape", "execution_count": null, "outputs": []}, {"metadata": {"id": "b1523415-c2d3-47fb-9a82-2bd547bde920"}, "cell_type": "markdown", "source": "### Step 4: Data understanding"}, {"metadata": {"id": "46813b72-e473-423d-b737-721d86dcf233", "scrolled": true}, "cell_type": "code", "source": "data.describe()", "execution_count": null, "outputs": []}, {"metadata": {"id": "e0446278-a6d4-4bad-9ac9-69ac498159bd"}, "cell_type": "code", "source": "# Uncomment if you would like to see the profile report\n\n#Uncomment and run once to install the package in your runtime environment\n#!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip", "execution_count": null, "outputs": []}, {"metadata": {"id": "fe284a664c9b43038bd5598753d47d6e"}, "cell_type": "code", "source": "# Uncomment if you would like to see the profile report\n#from pandas_profiling import ProfileReport\n    \n#profile = ProfileReport(data, title=\"Data Profiling Report\")\n#profile.to_widgets()", "execution_count": null, "outputs": []}, {"metadata": {"id": "5ea7f08e-707d-425d-9592-55025fca2749"}, "cell_type": "markdown", "source": "### Step 5: Build the sklearn pipeline and the Random Forest model\n"}, {"metadata": {"id": "0323b9a8-81d8-4c01-b013-56c0fffe7922"}, "cell_type": "code", "source": "# Define input data to the model\nX = data.drop(['ID','CHURN'], axis=1)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a4cc6b30-ccfd-4cc1-beba-87e21d396d3d"}, "cell_type": "code", "source": "# Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\nle = LabelEncoder()\ny = le.fit_transform(data['CHURN'])", "execution_count": null, "outputs": []}, {"metadata": {"id": "3d551ca4-1bff-459b-8c6e-656f8c1971de"}, "cell_type": "code", "source": "label_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {"id": "f9cacfb9-5dec-48be-9d7c-a86a31963973"}, "cell_type": "code", "source": "# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d54e72a7-5b50-4843-8d95-79b6f713e761"}, "cell_type": "markdown", "source": "#### Use the DataFrameMapper class to declare transformations and variable imputations.\n\n* LabelBinarizer - Converts a categorical variable into a dummy variable (aka binary variable)\n* StandardScaler - Standardize features by removing the mean and scaling to unit variance, z = (x - u) / s\n\nSee docs: \n* https://github.com/scikit-learn-contrib/sklearn-pandas\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer\n* https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"}, {"metadata": {"id": "f4f15ad7-5688-46ec-9582-9dfb874fe45c"}, "cell_type": "code", "source": "\nmapper_good = DataFrameMapper([\n    (['Gender'], LabelBinarizer()),\n    (['Status'], LabelBinarizer()),\n    (['CarOwner'], LabelBinarizer()),\n    (['Paymethod'], LabelBinarizer()),\n    (['MembershipPlan'], LabelBinarizer()),\n    (['Children'],  StandardScaler()),\n    (['EstIncome'],  StandardScaler()),\n    (['Age'],  StandardScaler()),\n    (['AvgMonthlySpend'],  StandardScaler()),\n    (['CustomerSupportCalls'],  StandardScaler())], default=False)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "ec338d09-232c-4da7-b019-45f44e9b3cdf"}, "cell_type": "code", "source": "# Instantiate the Classifier\nrandom_forest = RandomForestClassifier(random_state=5)\n\n# Define the steps in the pipeline to sequentially apply a list of transforms and the estimator, i.e. RandomForestClassifier\nsteps = [('mapper', mapper_good),('RandonForestClassifier', random_forest)]\npipeline = sklearn.pipeline.Pipeline(steps)\n\n# train the model\nmodel=pipeline.fit( X_train, y_train )\n\nmodel", "execution_count": null, "outputs": []}, {"metadata": {"id": "1460a16a-7ca9-4846-b2ca-57b00aa7c562"}, "cell_type": "code", "source": "# Display Label Mapping to assist with interpretation of the model\nlabel_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {"id": "3bad804d-9271-49e1-b274-d77984eb2742"}, "cell_type": "code", "source": "### call pipeline.predict() on your X_test data to make a set of test predictions\ny_prediction = pipeline.predict( X_test )\n\n### test your predictions using sklearn.classification_report()\nreport = sklearn.metrics.classification_report( y_test, y_prediction )\n\n### and print the report\nprint(report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "46612efe-53cb-465e-bac9-8f9d4f3b2002"}, "cell_type": "markdown", "source": "###  Step 6:  Tune the model to find the best model"}, {"metadata": {"id": "fdc8a16d-1de9-4983-bfe3-1dbe638ded3d"}, "cell_type": "code", "source": "# List keys to the model param to tune\n#model.get_params().keys()", "execution_count": null, "outputs": []}, {"metadata": {"id": "61e191c5-293b-49e5-af1e-dd64dba72cb5"}, "cell_type": "code", "source": "parameters = { 'RandonForestClassifier__max_depth': [5,8,10],\n               'RandonForestClassifier__n_estimators': [150,180,200]}", "execution_count": null, "outputs": []}, {"metadata": {"id": "a9a6432f-cdcb-49e8-8d49-dfccf9780b26"}, "cell_type": "code", "source": "grid_obj = GridSearchCV(estimator=model, param_grid=parameters,  cv=3)", "execution_count": null, "outputs": []}, {"metadata": {"id": "23c7bf96-178b-47a2-a6fb-6a48a7bab625"}, "cell_type": "code", "source": "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train,y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "20815230-7c38-41ea-811a-c2de8adaace5"}, "cell_type": "code", "source": "# Get the estimator\nbest_clf = grid_fit.best_estimator_", "execution_count": null, "outputs": []}, {"metadata": {"id": "f19e4edc-522e-47db-8488-87856eb53250"}, "cell_type": "code", "source": "best_predictions = best_clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {"id": "865bba0b-75e4-44d1-b9a8-1e4cbf905b64"}, "cell_type": "code", "source": "best_predictions_report = sklearn.metrics.classification_report( y_test, best_predictions )", "execution_count": null, "outputs": []}, {"metadata": {"id": "b3e805c0-14e9-43ea-91fd-b7436e2513ac"}, "cell_type": "code", "source": "print('Results of best fitted model: \\n\\n',best_predictions_report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "e4118274-0238-41ad-b09c-bae84635e70f"}, "cell_type": "code", "source": "print('Results of default model: \\n\\n',report)", "execution_count": null, "outputs": []}, {"metadata": {"id": "aa75bcd2-161f-4432-9292-7ef1a9669d0e"}, "cell_type": "code", "source": "m_step=pipeline.named_steps['mapper']", "execution_count": null, "outputs": []}, {"metadata": {"id": "7480eeef-6d18-4339-962d-3224933bc2f4"}, "cell_type": "code", "source": "m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {"id": "d2b7baae-b1e6-4e3e-ac3c-39e6d22637bb"}, "cell_type": "code", "source": "features = m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {"id": "457101a8-04be-4153-bb47-ab228a64ac93"}, "cell_type": "code", "source": "# Get the features importance\nimportances = pipeline.named_steps['RandonForestClassifier'][1].feature_importances_\nindices = np.argsort(importances)", "execution_count": null, "outputs": []}, {"metadata": {"id": "1ac1593d-3334-423a-8ec1-8ad817a68065"}, "cell_type": "code", "source": "plt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b',align='center')\nplt.yticks(range(len(indices)), (np.array(features))[indices])\nplt.xlabel('Relative Importance')", "execution_count": null, "outputs": []}, {"metadata": {"id": "a7cdf7d2-641e-4fad-962b-5b34205fd46f"}, "cell_type": "markdown", "source": "### Step 7: Save Model in the Project\n"}, {"metadata": {"id": "77cbeef2-3e0d-496b-8f8e-3d0c2df8c741"}, "cell_type": "code", "source": "# get the Project ID and set the location to save the model to the project\nfrom ibm_watson_machine_learning import APIClient\nimport os\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"4.0\"\n}\n\nclient = APIClient(wml_credentials)\n\nproject_id = os.environ['PROJECT_ID']\nclient.set.default_project(project_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "33e6a180-d066-4fcc-87ef-42e221aafa13"}, "cell_type": "code", "source": "# Provide metadata and save the model into the repository. After running this cell, the model will be displayed in the Assets view\n\nmodel_name = 'customer_churn_model'\nsoftware_spec_uid = client.software_specifications.get_uid_by_name('default_py3.7_opence')\n\nmetadata = {\n    client.repository.ModelMetaNames.NAME: model_name,\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.23\"\n}\n\nstored_model_details = client.repository.store_model(pipeline,\n                                               meta_props=metadata,\n                                               training_data=X_train,\n                                               training_target=y_train)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b5b1bd8e-8dfc-4451-8875-2aca22f22607"}, "cell_type": "markdown", "source": "**In this version of the notebook we will perform deployment steps in the UI.**"}, {"metadata": {"id": "ed632712-e8b0-49db-a369-200307e34ab9"}, "cell_type": "markdown", "source": "**Author:**  Sidney Phoon and Elena Lowery<br/>\n**Date:**  September 2021"}, {"metadata": {"id": "afdcdb85-e169-4847-ae1c-298948c6f27d"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}